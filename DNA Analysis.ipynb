{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNA Sequences Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bacteria and other micro-organisms have been very import for the field of biology.\n",
    "In this project E. Coli Bacteria DNA nucleotide sequences have been classified based on its Promoter class.\n",
    "\n",
    "We shall explore the world of Bioinformatics by using Markov models, K-nearest neighbor (KNN) algorithms, Support Vector Machines (widely used), adaboost algorithm, Decision tree, Random forest classifier and such more algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Finally we shall test our data based on the training data model and compare the results of all the algorithms through classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.5.6 |Anaconda, Inc.| (default, Aug 26 2018, 21:41:56) \n",
      "[GCC 7.3.0]\n",
      "Numpy: 1.15.2\n",
      "Sklearn: 0.20.0\n",
      "Pandas: 0.23.4\n"
     ]
    }
   ],
   "source": [
    "# Lets start with importing all the required modules and packages and ensure their versions\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "print('Python: {}'.format(sys.version))\n",
    "print('Numpy: {}'.format(np.__version__))\n",
    "print('Sklearn: {}'.format(sklearn.__version__))\n",
    "print('Pandas: {}'.format(pd.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step:1 Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving further lets import our data from UCI machine learning repo\n",
    "\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/molecular-biology/promoter-gene-sequences/promoters.data'\n",
    "\n",
    "# Explicitly defining the features(columns) of our data\n",
    "col_names = ['Class','id','Sequence']\n",
    "\n",
    "data  =pd.read_csv(url,names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>id</th>\n",
       "      <th>Sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>+</td>\n",
       "      <td>S10</td>\n",
       "      <td>\\t\\ttactagcaatacgcttgcgttcggtggttaagtatgtataat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>+</td>\n",
       "      <td>AMPC</td>\n",
       "      <td>\\t\\ttgctatcctgacagttgtcacgctgattggtgtcgttacaat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>+</td>\n",
       "      <td>AROH</td>\n",
       "      <td>\\t\\tgtactagagaactagtgcattagcttatttttttgttatcat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>+</td>\n",
       "      <td>DEOP2</td>\n",
       "      <td>\\taattgtgatgtgtatcgaagtgtgttgcggagtagatgttagaa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>+</td>\n",
       "      <td>LEU1_TRNA</td>\n",
       "      <td>\\ttcgataattaactattgacgaaaagctgaaaaccactagaatgc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Class         id                                           Sequence\n",
       "0     +        S10  \\t\\ttactagcaatacgcttgcgttcggtggttaagtatgtataat...\n",
       "1     +       AMPC  \\t\\ttgctatcctgacagttgtcacgctgattggtgtcgttacaat...\n",
       "2     +       AROH  \\t\\tgtactagagaactagtgcattagcttatttttttgttatcat...\n",
       "3     +      DEOP2  \\taattgtgatgtgtatcgaagtgtgttgcggagtagatgttagaa...\n",
       "4     +  LEU1_TRNA  \\ttcgataattaactattgacgaaaagctgaaaaccactagaatgc..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['t', 'a', 'c', 't', 'a', 'g', 'c', 'a', 'a', 't', 'a', 'c', 'g', 'c', 't', 't', 'g', 'c', 'g', 't', 't', 'c', 'g', 'g', 't', 'g', 'g', 't', 't', 'a', 'a', 'g', 't', 'a', 't', 'g', 't', 'a', 't', 'a', 'a', 't', 'g', 'c', 'g', 'c', 'g', 'g', 'g', 'c', 't', 't', 'g', 't', 'c', 'g', 't', '+']\n"
     ]
    }
   ],
   "source": [
    "# We now see here that our data has tab spaces between id and sequence, thus we see '\\t' in front of Sequence string\n",
    "\n",
    "# removing those extra charaters from sequence string\n",
    "classes = data.loc[:, 'Class']\n",
    "sequences = list(data.loc[:,'Sequence'])\n",
    "\n",
    "dataset = {}\n",
    "\n",
    "for i, seq in enumerate(sequences):\n",
    "    \n",
    "    nucleotides = list(seq)\n",
    "    nucleotides = [x for x in nucleotides if x != '\\t']\n",
    "    \n",
    "    nucleotides.append(classes[i])\n",
    "    \n",
    "    dataset[i] = nucleotides\n",
    "    \n",
    "print(dataset[0])\n",
    "# Here we get all the sequence of DNA base pairs (like a:adenine, t:thymine, g:guanine, c:cytosine)\n",
    "# Also the last term is the class our nucleotide(promotor class either +/-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0   1   2   3   4   5   6   7   8   9   ... 96  97  98  99  100 101 102 103  \\\n",
      "0   t   t   g   a   t   a   c   t   c   t ...   c   c   t   a   g   c   g   c   \n",
      "1   a   g   t   a   c   g   a   t   g   t ...   c   g   a   g   a   c   t   g   \n",
      "2   c   c   a   t   g   g   g   t   a   t ...   g   c   t   a   g   t   a   c   \n",
      "3   t   t   c   t   a   g   g   c   c   t ...   a   t   g   g   a   c   t   g   \n",
      "4   a   a   t   g   t   g   g   t   t   a ...   g   a   a   g   g   a   t   a   \n",
      "\n",
      "  104 105  \n",
      "0   c   t  \n",
      "1   t   a  \n",
      "2   c   a  \n",
      "3   g   c  \n",
      "4   t   a  \n",
      "\n",
      "[5 rows x 106 columns]\n"
     ]
    }
   ],
   "source": [
    "# now moving on lets convert the above dict into pandas dataframe\n",
    "\n",
    "df = pd.DataFrame(dataset)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0  1  2  3  4  5  6  7  8  9  ... 48 49 50 51 52 53 54 55 56 57\n",
      "0  t  a  c  t  a  g  c  a  a  t ...  g  c  t  t  g  t  c  g  t  +\n",
      "1  t  g  c  t  a  t  c  c  t  g ...  c  a  t  c  g  c  c  a  a  +\n",
      "2  g  t  a  c  t  a  g  a  g  a ...  c  a  c  c  c  g  g  c  g  +\n",
      "3  a  a  t  t  g  t  g  a  t  g ...  a  a  c  a  a  a  c  t  c  +\n",
      "4  t  c  g  a  t  a  a  t  t  a ...  c  c  g  t  g  g  t  a  g  +\n",
      "\n",
      "[5 rows x 58 columns]\n"
     ]
    }
   ],
   "source": [
    "# Above dataframe doesn't look what we wanted so try and transpose it\n",
    "\n",
    "df = df.transpose()\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  1  2  3  4  5  6  7  8  9  ...  48 49 50 51 52 53 54 55 56 Class\n",
      "0  t  a  c  t  a  g  c  a  a  t  ...   g  c  t  t  g  t  c  g  t     +\n",
      "1  t  g  c  t  a  t  c  c  t  g  ...   c  a  t  c  g  c  c  a  a     +\n",
      "2  g  t  a  c  t  a  g  a  g  a  ...   c  a  c  c  c  g  g  c  g     +\n",
      "3  a  a  t  t  g  t  g  a  t  g  ...   a  a  c  a  a  a  c  t  c     +\n",
      "4  t  c  g  a  t  a  a  t  t  a  ...   c  c  g  t  g  g  t  a  g     +\n",
      "\n",
      "[5 rows x 58 columns]\n"
     ]
    }
   ],
   "source": [
    "# Changing the column name 57 to Class for better readability\n",
    "df.rename(columns={57: 'Class'},inplace=True) \n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    +\n",
      "1    +\n",
      "2    +\n",
      "3    +\n",
      "4    +\n",
      "Name: Class, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Now it looks more better with each column till 56 representing \n",
    "# base pairs of DNA (adenine,thymine, guanine, cytosine) and last column is of promotor class\n",
    "\n",
    "# What our final aim was also to predict the promotor class of the DNA sequence\n",
    "test = df.iloc[:,-1]\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's start to familiarize ourselves with the dataset so we can pick the most suitable algorithms for this data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>...</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>...</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>t</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>38</td>\n",
       "      <td>34</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>36</td>\n",
       "      <td>42</td>\n",
       "      <td>38</td>\n",
       "      <td>34</td>\n",
       "      <td>33</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>42</td>\n",
       "      <td>31</td>\n",
       "      <td>33</td>\n",
       "      <td>35</td>\n",
       "      <td>32</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>34</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0    1    2    3    4    5    6    7    8    9  ...    48   49   50  \\\n",
       "count   106  106  106  106  106  106  106  106  106  106  ...   106  106  106   \n",
       "unique    4    4    4    4    4    4    4    4    4    4  ...     4    4    4   \n",
       "top       t    a    a    c    a    a    a    a    a    a  ...     c    c    c   \n",
       "freq     38   34   30   30   36   42   38   34   33   36  ...    36   42   31   \n",
       "\n",
       "         51   52   53   54   55   56 Class  \n",
       "count   106  106  106  106  106  106   106  \n",
       "unique    4    4    4    4    4    4     2  \n",
       "top       t    t    c    c    c    t     -  \n",
       "freq     33   35   32   29   29   34    53  \n",
       "\n",
       "[4 rows x 58 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploring the data\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0     1     2     3     4     5     6     7     8     9  ...      48  \\\n",
      "t  38.0  26.0  27.0  26.0  22.0  24.0  30.0  32.0  32.0  28.0  ...    21.0   \n",
      "c  27.0  22.0  21.0  30.0  19.0  18.0  21.0  20.0  22.0  22.0  ...    36.0   \n",
      "a  26.0  34.0  30.0  22.0  36.0  42.0  38.0  34.0  33.0  36.0  ...    23.0   \n",
      "g  15.0  24.0  28.0  28.0  29.0  22.0  17.0  20.0  19.0  20.0  ...    26.0   \n",
      "-   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...     NaN   \n",
      "+   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...     NaN   \n",
      "\n",
      "     49    50    51    52    53    54    55    56  Class  \n",
      "t  22.0  23.0  33.0  35.0  30.0  23.0  29.0  34.0    NaN  \n",
      "c  42.0  31.0  32.0  21.0  32.0  29.0  29.0  17.0    NaN  \n",
      "a  24.0  28.0  27.0  25.0  22.0  26.0  24.0  27.0    NaN  \n",
      "g  18.0  24.0  14.0  25.0  22.0  28.0  24.0  28.0    NaN  \n",
      "-   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   53.0  \n",
      "+   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   53.0  \n",
      "\n",
      "[6 rows x 58 columns]\n"
     ]
    }
   ],
   "source": [
    "# Describe doesn't tell much when our data is of object(text) datatype, so we should count the number of each seq.\n",
    "\n",
    "val_count = []\n",
    "\n",
    "for name in df.columns:\n",
    "    val_count.append(df[name].value_counts())\n",
    "\n",
    "info = pd.DataFrame(val_count)\n",
    "info = info.transpose()\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0_a  0_c  0_g  0_t  1_a  1_c  1_g  1_t  2_a  2_c   ...     55_a  55_c  \\\n",
      "0    0    0    0    1    1    0    0    0    0    1   ...        0     0   \n",
      "1    0    0    0    1    0    0    1    0    0    1   ...        1     0   \n",
      "2    0    0    1    0    0    0    0    1    1    0   ...        0     1   \n",
      "3    1    0    0    0    1    0    0    0    0    0   ...        0     0   \n",
      "4    0    0    0    1    0    1    0    0    0    0   ...        1     0   \n",
      "\n",
      "   55_g  55_t  56_a  56_c  56_g  56_t  Class_+  Class_-  \n",
      "0     1     0     0     0     0     1        1        0  \n",
      "1     0     0     1     0     0     0        1        0  \n",
      "2     0     0     0     0     1     0        1        0  \n",
      "3     0     1     0     1     0     0        1        0  \n",
      "4     0     0     0     0     1     0        1        0  \n",
      "\n",
      "[5 rows x 230 columns]\n"
     ]
    }
   ],
   "source": [
    "# Our dataset has equal counts of both the classes promotor(+) as well as non-promotor(-)\n",
    "\n",
    "# But knowing all this then too we can't apply ML models directly on data in 'String' formats\n",
    "# So we need to convert object datatype into that of numerical data type \n",
    "\n",
    "# Let's use pandas get_dummies function for that\n",
    "numerical_df = pd.get_dummies(df)\n",
    "print(numerical_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0_a  0_c  0_g  0_t  1_a  1_c  1_g  1_t  2_a  2_c  ...    54_t  55_a  55_c  \\\n",
      "0    0    0    0    1    1    0    0    0    0    1  ...       0     0     0   \n",
      "1    0    0    0    1    0    0    1    0    0    1  ...       0     1     0   \n",
      "2    0    0    1    0    0    0    0    1    1    0  ...       0     0     1   \n",
      "3    1    0    0    0    1    0    0    0    0    0  ...       0     0     0   \n",
      "4    0    0    0    1    0    1    0    0    0    0  ...       1     1     0   \n",
      "\n",
      "   55_g  55_t  56_a  56_c  56_g  56_t  Class  \n",
      "0     1     0     0     0     0     1      1  \n",
      "1     0     0     1     0     0     0      1  \n",
      "2     0     0     0     0     1     0      1  \n",
      "3     0     1     0     1     0     0      1  \n",
      "4     0     0     0     0     1     0      1  \n",
      "\n",
      "[5 rows x 229 columns]\n"
     ]
    }
   ],
   "source": [
    "# Great! but we see that our class is also divided into 2 columns though it is only has binary categories\n",
    "\n",
    "df = numerical_df.drop(columns=['Class_-'])\n",
    "\n",
    "df.rename(columns = {'Class_+': 'Class'}, inplace=True)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Spliting our data into training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Train test split from sklearn.model_selection\n",
    "from sklearn import model_selection\n",
    "\n",
    "# Create X as features and y as label\n",
    "X = np.array(df.drop(['Class'], 1))\n",
    "y = np.array(df['Class'])\n",
    "\n",
    "# defining seed for reproducibility\n",
    "seed = 1\n",
    "\n",
    "# spliting data into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.25, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Applying Machine learning algorithms to our training sets\n",
    "\n",
    "Now that we have preprocessed the data and built our training and testing datasets, we can start to deploy different classification algorithms. It's relatively easy to test multiple models; as a result, we will compare and contrast the performance of ten different algorithms on some performance metrics such as accuracy_score and classification_report (best way)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbors: 0.823214 (0.113908)\n",
      "Testing Scores\n",
      "Nearest Neighbors\n",
      "0.7777777777777778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.65      0.79        17\n",
      "           1       0.62      1.00      0.77        10\n",
      "\n",
      "   micro avg       0.78      0.78      0.78        27\n",
      "   macro avg       0.81      0.82      0.78        27\n",
      "weighted avg       0.86      0.78      0.78        27\n",
      "\n",
      "Random Forest: 0.633929 (0.150308)\n",
      "Testing Scores\n",
      "Random Forest\n",
      "0.5925925925925926\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.41      0.56        17\n",
      "           1       0.47      0.90      0.62        10\n",
      "\n",
      "   micro avg       0.59      0.59      0.59        27\n",
      "   macro avg       0.67      0.66      0.59        27\n",
      "weighted avg       0.73      0.59      0.58        27\n",
      "\n",
      "Neural Net: 0.887500 (0.087500)\n",
      "Testing Scores\n",
      "Neural Net\n",
      "0.9259259259259259\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.94        17\n",
      "           1       0.83      1.00      0.91        10\n",
      "\n",
      "   micro avg       0.93      0.93      0.93        27\n",
      "   macro avg       0.92      0.94      0.92        27\n",
      "weighted avg       0.94      0.93      0.93        27\n",
      "\n",
      "Decision Tree: 0.721429 (0.174818)\n",
      "Testing Scores\n",
      "Decision Tree\n",
      "0.8518518518518519\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.76      0.87        17\n",
      "           1       0.71      1.00      0.83        10\n",
      "\n",
      "   micro avg       0.85      0.85      0.85        27\n",
      "   macro avg       0.86      0.88      0.85        27\n",
      "weighted avg       0.89      0.85      0.85        27\n",
      "\n",
      "AdaBoost: 0.925000 (0.114564)\n",
      "Testing Scores\n",
      "AdaBoost\n",
      "0.8518518518518519\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.76      0.87        17\n",
      "           1       0.71      1.00      0.83        10\n",
      "\n",
      "   micro avg       0.85      0.85      0.85        27\n",
      "   macro avg       0.86      0.88      0.85        27\n",
      "weighted avg       0.89      0.85      0.85        27\n",
      "\n",
      "Gaussian Process: 0.873214 (0.056158)\n",
      "Testing Scores\n",
      "Gaussian Process\n",
      "0.8888888888888888\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.82      0.90        17\n",
      "           1       0.77      1.00      0.87        10\n",
      "\n",
      "   micro avg       0.89      0.89      0.89        27\n",
      "   macro avg       0.88      0.91      0.89        27\n",
      "weighted avg       0.91      0.89      0.89        27\n",
      "\n",
      "Naive Bayes: 0.837500 (0.137500)\n",
      "Testing Scores\n",
      "Naive Bayes\n",
      "0.9259259259259259\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.94        17\n",
      "           1       0.83      1.00      0.91        10\n",
      "\n",
      "   micro avg       0.93      0.93      0.93        27\n",
      "   macro avg       0.92      0.94      0.92        27\n",
      "weighted avg       0.94      0.93      0.93        27\n",
      "\n",
      "SVM Linear: 0.850000 (0.108972)\n",
      "Testing Scores\n",
      "SVM Linear\n",
      "0.9629629629629629\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        17\n",
      "           1       0.91      1.00      0.95        10\n",
      "\n",
      "   micro avg       0.96      0.96      0.96        27\n",
      "   macro avg       0.95      0.97      0.96        27\n",
      "weighted avg       0.97      0.96      0.96        27\n",
      "\n",
      "SVM RBF: 0.737500 (0.117925)\n",
      "Testing Scores\n",
      "SVM RBF\n",
      "0.7777777777777778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.65      0.79        17\n",
      "           1       0.62      1.00      0.77        10\n",
      "\n",
      "   micro avg       0.78      0.78      0.78        27\n",
      "   macro avg       0.81      0.82      0.78        27\n",
      "weighted avg       0.86      0.78      0.78        27\n",
      "\n",
      "SVM Sigmoid: 0.569643 (0.159209)\n",
      "Testing Scores\n",
      "SVM Sigmoid\n",
      "0.4444444444444444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.12      0.21        17\n",
      "           1       0.40      1.00      0.57        10\n",
      "\n",
      "   micro avg       0.44      0.44      0.44        27\n",
      "   macro avg       0.70      0.56      0.39        27\n",
      "weighted avg       0.78      0.44      0.34        27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# We can start building algorithms! We'll need to import each algorithm we plan on using from sklearn.\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# defining scoring method\n",
    "scoring = 'accuracy'\n",
    "\n",
    "# we have 10 models to train\n",
    "names = [\"Nearest Neighbors\", \"Random Forest\",\"Neural Net\",\n",
    "         \"Decision Tree\",\"AdaBoost\",\"Gaussian Process\",\n",
    "         \"Naive Bayes\", \"SVM Linear\", \"SVM RBF\", \"SVM Sigmoid\"]\n",
    "\n",
    "# lets define each of the classifier\n",
    "classifier = [\n",
    "    KNeighborsClassifier(n_neighbors=3),\n",
    "    RandomForestClassifier(n_estimators=10,max_depth=5,max_features=1),\n",
    "    MLPClassifier(alpha=1),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianProcessClassifier(1.0*RBF(1.0)),\n",
    "    GaussianNB(),\n",
    "    SVC(kernel = 'linear'),\n",
    "    SVC(kernel = 'rbf'),\n",
    "    SVC(kernel='sigmoid')\n",
    "]\n",
    "\n",
    "models = zip(names,classifier)\n",
    "\n",
    "# evaluate models\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "\n",
    "for name,model in models:\n",
    "    kfold = model_selection.KFold(n_splits=10,random_state=seed)\n",
    "    cv_results = model_selection.cross_val_score(model,X_train,y_train,cv=kfold,scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    formating = \"%s: %f (%f)\" %(name, cv_results.mean(),cv_results.std())\n",
    "    print(formating)\n",
    "    print(\"Testing Scores\")\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    print(name)\n",
    "    \n",
    "    print(accuracy_score(y_test, predictions))\n",
    "    print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remember, performance on the training data is not that important. We want to know how well our algorithms can generalize to new data.\n",
    "\n",
    "### Finally, **SVM linear** performs the best and also it is not that surprising because, the reason SVM is used in the field of Bioinformatics widely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definations of attributes in classification report\n",
    "Accuracy - ratio of correctly predicted observation to the total observations. \n",
    "\n",
    "Precision - (false positives) ratio of correctly predicted positive observations to the total predicted positive observations\n",
    "\n",
    "Recall (Sensitivity) - (false negatives) ratio of correctly predicted positive observations to the all observations in actual class - yes.\n",
    "\n",
    "F1 score - F1 Score is the weighted average of Precision and Recall. Therefore, this score takes both false positives and false"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
